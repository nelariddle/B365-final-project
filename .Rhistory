V2[, 5] == 2 && V2[, 9] == "N")
V2[, 5] == 2 && V2[, 9] == "N"
V2[, 5] == 2 & V2[, 9] == "N"
!is.na(V2[, 5] == 2 & V2[, 9] == "N")
is.true(V2[, 5] == 2 & V2[, 9] == "N")
isTRUE(V2[, 5] == 2 & V2[, 9] == "N")
(V2[, 5] == 2 & V2[, 9] == "N")
sum((V2[, 5] == 2 & V2[, 9] == "N")==1)
(V2[, 5] == 2 & V2[, 9] == "N") =="TRUE"
(V2[, 5] == 2 & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 5] == 2 & V2[, 9] == "N")
sum((V2[, 5] == 2 & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 5] == 2 & V2[, 9] == "N"))
Q1 = array(0,dim=c(2,7))
for (c in 1:2) {
for (v in 1:7) {
if(c==1) {Q1[c,v] = sum((V2[, 5] == 2 & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 5] == 2 & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q1[c,v] = sum((V2[, 5] == 2 & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 5] == 2 & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
Q1
Q1 = array(0,dim=c(2,7))
for (c in 1:2) {
for (v in 1:7) {
if(c==1) {Q1[c,v] = sum((V2[, 5] == v & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 5] == v & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q1[c,v] = sum((V2[, 5] == v & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 5] == v & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
Q1
Q1 = array(0,dim=c(2,7))
for (c in 1:2) {
for (v in 1:7) {
if(c==1) {Q1[c,v] = sum((V2[, 5] == v & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 5] == v & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q1[c,v] = sum((V2[, 5] == v & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 5] == v & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
Q1
Q2 = array(0,dim=c(2,3))
for (c in 1:2) {
for (v in 1:3) {
if(c==1) {Q2[c,v] = sum((V2[, 6] == v & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 6] == v & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q2[c,v] = sum((V2[, 6] == v & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 6] == v & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
print(Q1)
print(Q2)
for (c in 1:2) {
for (v in c("P","PS","S")) {
if(c==1) {Q2[c,v] = sum((V2[, 6] == v & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 6] == v & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q2[c,v] = sum((V2[, 6] == v & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 6] == v & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
Q2 = array(0,dim=c(2,3))
for (c in 1:2) {
for (v in c("P","PS","S")) {
if(c==1) {Q2[c,v] = sum((V2[, 6] == v & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 6] == v & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q2[c,v] = sum((V2[, 6] == v & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 6] == v & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
for (v in c("P","PS","S")) print(v)
"P" in c("P","PS","S")
clist= c("P","PS","S")
clist[1]
Q2 = array(0,dim=c(2,3))
clist= c("P","PS","S")
for (c in 1:2) {
for (v in  3) {
if(c==1) {Q2[c,v] = sum((V2[, 6] == clist[v] & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 6] == clist[v] & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q2[c,v] = sum((V2[, 6] == clist[v] & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 6] == clist[v] & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
print(Q1)
print(Q2)
Q2 = array(0,dim=c(2,3))
clist= c("P","PS","S")
for (c in 1:2) {
for (v in 1:3) {
if(c==1) {Q2[c,v] = sum((V2[, 6] == clist[v] & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 6] == clist[v] & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q2[c,v] = sum((V2[, 6] == clist[v] & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 6] == clist[v] & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
print(Q1)
print(Q2)
t=table(V[,c("age","vote")])
P = rep(0,2)
P[1] = length(yes) / length(V)
P[2] = length(no) / length(V)
print(P)
V <- V[no | yes,]
V[,5] <- floor(V[, 5]/10)
print(V)
t=table(V[,c("age","vote")])
P = rep(0,2)
P[1] = length(yes) / length(V)
P[2] = length(no) / length(V)
print(P)
length(yes)
yes
P[1] = sum(yes) / length(V)
P[2] = sum(no) / length(V)
print(P)
P[1] = sum(yes & !is.na(yes)) / length(V)
P[2] = sum(no & !is.na(no)) / length(V)
print(P)
length(V)
P = rep(0,2)
P[1] = sum(yes & !is.na(yes)) / length(V[,9])
P[2] = sum(no & !is.na(no)) / length(V[,9])
print(P)
c_head = array(0,dim=c(1,7,3))
for (a1 in 1:7) {
for (a2 in 1:3) {
c_head[,a1,a2] = which.max(Q1[,a1] * Q2[,a2] * P)
}
}
for (a1 in 1:7) {
for (a2 in 1:3) {
c_head[,a1,a2] = which.max(Q1[,a1] * Q2[,a2] * P)
}
}
print(c_head)
# (b)
V2 <- read.csv2("CSCI B-365/chilean_voting.csv", stringsAsFactors=FALSE, sep=",")
#yes2 <- (V2[, "vote"] == "Y") #& !(is.na(x[,"vote"])))
#no2 <- (V2[, "vote"] == "N" )#& (is.na(x[,"vote"])))
#V2 <- V2[no2 | yes2,]
V2[,5] <- floor(V2[, 5]/10)
Q1 = array(0,dim=c(2,7))
for (c in 1:2) {
for (v in 1:7) {
if(c==1) {Q1[c,v] = sum((V2[, 5] == v & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 5] == v & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q1[c,v] = sum((V2[, 5] == v & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 5] == v & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
Q1
Q2 = array(0,dim=c(2,3))
clist= c("P","PS","S")
for (c in 1:2) {
for (v in 1:3) {
if(c==1) {Q2[c,v] = sum((V2[, 6] == clist[v] & V2[, 9] == "N") =="TRUE" & !is.na(V2[, 6] == clist[v] & V2[, 9] == "N"))/sum(V2[,9] == "N" & !(is.na(V2[,9])))}
if(c==2) {Q2[c,v] = sum((V2[, 6] == clist[v] & V2[, 9] == "Y") =="TRUE" & !is.na(V2[, 6] == clist[v] & V2[, 9] == "Y"))/sum(V2[,9] == "Y" & !(is.na(V2[,9])))}
}
}
print(Q1)
print(Q2)
c_head = array(0,dim=c(1,7,3))
for (a1 in 1:7) {
for (a2 in 1:3) {
c_head[,a1,a2] = which.max(Q1[,a1] * Q2[,a2] * P)
}
}
print(c_head)
``
library(rpart);
set.seed(1234);  # want random experiments to be exaclty repeatable
n = 200;	 # number examples
y = rep(0:9, length = n);	# the true classes
temp = c(1,1,1,0,1,1,1,		# pattern for 0
0,0,1,0,0,1,0,		# pattern for 1
1,0,1,1,1,0,1,		# pattern for 2
1,0,1,1,0,1,1,		# ...
0,1,1,1,0,1,1,
1,1,0,1,0,1,1,
0,1,0,1,1,1,1,
1,0,1,0,0,1,0,
1,1,1,1,1,1,1,
1,1,1,1,0,1,0);
lights = matrix(temp,10,7,byrow=T);	# light[i,] is bit pattern for i-1
temp1 = matrix(rbinom(n*7,1, .9), n, 7)
temp1 = ifelse(lights[y+1,] == 1, temp1, 1-temp1); #  digits with flipped bits
temp2 = matrix(rbinom(n*17,1,.5), n, 17)  # random lights (noisy worthless features)
x = cbind(temp1,temp2);  # variables 8 ... 24 are useless noise
fit = rpart(y ~ x, method = "class", control = rpart.control(xval=10,minbucket=2,cp=0));
#plot(fit);text(fit)
printcp(fit)  	# note the included noise variables
fit9 = prune(fit,cp=.0166);  # anything in the range .01666 to .01 gives same result
print(fit9)
printcp(fit9)
# Question 2.
data(iris3)
dimnames(iris3)
dimnames(cars)
# Question 2.
data(iris3)
dimnames(iris3)
x = iris3[,'Sepal L.','Setosa']
y = iris3[,'Sepal W.','Setosa']
n = length(x)
plot(x,y)
x = iris3[,'Sepal L.','Setosa']
y = iris3[,'Sepal W.','Setosa']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b are ", a, b, "\n")
data(cars)
x = cars$speed
y = cars$dist
n = length(x);
plot(x,y)
xbar = sum(x)/n;	  # this is boilerplate taken from simple_regression.r
ybar = sum(y)/n;
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)  # from our calculations
a = (ybar - b)/xbar
abline(b,a)			# add the line that fits the data
# abline plots line with slope b and y intercept a
cat("a and b are ", a, b, "\n")
# Question 2.
data(iris3)
dimnames(iris3)
x = iris3[,'Sepal L.','Setosa']
y = iris3[,'Sepal W.','Setosa']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for setosa are ", a, b, "\n")
x = iris3[,'Sepal L.','Versicolor']
y = iris3[,'Sepal W.','Versicolor']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for versicolor are ", a, b, "\n")
x = iris3[,'Sepal L.','Virgincia']
y = iris3[,'Sepal W.','Virgincia']
n = length(x)
plot(x,y)
x = iris3[,'Sepal L.','Virginica']
y = iris3[,'Sepal W.','Virginica']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for virgincia are ", a, b, "\n")
# Question 2.
data(iris3)
dimnames(iris3)
x = iris3[,'Sepal L.','Setosa']
y = iris3[,'Sepal W.','Setosa']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for setosa are ", a, b, "\n")
x = iris3[,'Sepal L.','Versicolor']
y = iris3[,'Sepal W.','Versicolor']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for versicolor are ", a, b, "\n")
x = iris3[,'Sepal L.','Virginica']
y = iris3[,'Sepal W.','Virginica']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for virgincia are ", a, b, "\n")
# (c)
TP1 = 10/12
FP1 = 0/288
ROC1 = sqrt((FP1 * FP1)+((1-TP1)*(1-TP1)))
cat("Model 1 ROC = ", ROC1)
# (c)
TP1 = 10/12
FP1 = 0/288
ROC1 = sqrt((FP1 * FP1)+((1-TP1)*(1-TP1)))
cat("Model 1 ROC = ", ROC1, "\n")
TP2 = 11/12
FP2 = 3/288
ROC2 = sqrt((FP2 * FP2)+((1-TP2)*(1-TP2)))
cat("Model 2 ROC = ", ROC2, "\n")
se = sqrt(585.6)
pnorm(199.5,184,se)-pnorm(170.5,184,se)
qnorm(0.975)
pbinom(2,89,.3)
pnorm(-5.713369)
2*qnorm(0.975)
qnorm(0.995)
231.634-qnorm(0.995)*(6.746499839/sqrt(50))
231.634+qnorm(0.995)*(6.746499839/sqrt(50))
q()
prior = rep(1/3,3);  # prior not very important in this example since data chosen to have 50 examples from each class
x = iris3[,'Sepal L.','Setosa']
y = iris3[,'Sepal W.','Setosa']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for setosa are ", a, b, "\n")
x = iris3[,'Sepal L.','Versicolor']
y = iris3[,'Sepal W.','Versicolor']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for versicolor are ", a, b, "\n")
x = iris3[,'Sepal L.','Virginica']
y = iris3[,'Sepal W.','Virginica']
n = length(x)
plot(x,y)
xbar = sum(x)/n
ybar = sum(y)/n
xybar = sum(x*y)/n
xsqbar = sum(x*x)/n
b = (ybar*xsqbar-xbar*xybar)/ (xsqbar - xbar*xbar)
a = (ybar - b)/xbar
abline(b,a)
cat("a and b for virgincia are ", a, b, "\n")
# (c)
TP1 = 10/12
FP1 = 0/288
ROC1 = sqrt((FP1 * FP1)+((1-TP1)*(1-TP1)))
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
# Loading package
library(e1071)
library(caTools)
library(caret)
install.packages("installr")
library(installr)
updateR()
# Installing Packages
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
# Loading package
library(e1071)
library(caTools)
library(caret)
data = read.csv("data-with-inflation.csv")
split <- sample.split(data, SplitRatio = 0.7)
train <- subset(data, split == "TRUE")
test <- subset(data, split == "FALSE")
split <- sample.split(data, SplitRatio = 0.5)
train <- subset(data, split == "TRUE")
data = read.csv("data-with-inflation.csv")
setwd("~/B365-final-project")
data = read.csv("data-with-inflation.csv")
dimnames(data)
split <- sample.split(data, SplitRatio = 0.5)
train <- subset(data, split == "TRUE")
test <- subset(data, split == "FALSE")
split <- sample.split(data, SplitRatio = 0.7)
train <- subset(data, split == "TRUE")
test <- subset(data, split == "FALSE")
train_scale <- scale(train[, 17:38])
test_scale <- scale(test[, 17:38])
set.seed(120)
classifier_cl <- naivebayes(NEWSALARY ~ ., data = train)
classifier_cl <- naiveBayes(NEWSALARY ~ ., data = train)
classifier_cl
y_pred <- predict(classifier_cl, newdata = test)
cm <- table(test$NEWSALARY, y_pred)
cm
confusionMatrix(cm)
split <- sample.split(data, SplitRatio = 0.7)
train <- subset(data, split == "TRUE")
test <- subset(data, split == "FALSE")
train_scale <- scale(train[, "AVG.STDNT.CUM.GPA"])
test_scale <- scale(test[, "AVG.STDNT.CUM.GPA"])
set.seed(120)
classifier_cl <- naiveBayes(NEWSALARY ~ ., data = train)
classifier_cl
y_pred <- predict(classifier_cl, newdata = test)
cm <- table(test$NEWSALARY, y_pred)
cm
confusionMatrix(cm)
data = read.csv("data-with-inflation.csv")
data
dimnames(data)
data[1,"NEWSALARY"]
# Creating classes for salaries
for (i in 1:nrow(data)) {
if (data[i,"NEWSALARY"] <= 75000) {
data[i,"SALARYCLASS"] = 0
}
else if (data[i,"NEWSALARY"] <= 100000) {
data[i,"SALARYCLASS"] = 1
}
else if (data[i,"NEWSALARY"] <= 125000) {
data[i,"SALARYCLASS"] = 2
}
else if (data[i,"NEWSALARY"] <= 150000) {
data[i,"SALARYCLASS"] = 3
}
else if (data[i,"NEWSALARY"] <= 175000) {
data[i,"SALARYCLASS"] = 4
}
else if (data[i,"NEWSALARY"] <= 200000) {
data[i,"SALARYCLASS"] = 5
}
else if (data[i,"NEWSALARY"] > 100000) {
data[i,"SALARYCLASS"] = 6
}
}
data[1,"SALARYCLASS"]
write.csv(data, "data-with-salary-class.csv")
# Loading package
library(e1071)
library(caTools)
library(caret)
data = read.csv("data-with-inflation.csv")
dimnames(data)
data = read.csv("data-with-salary-class.csv")
dimnames(data)
split <- sample.split(data, SplitRatio = 0.7)
train <- subset(data, split == "TRUE")
test <- subset(data, split == "FALSE")
train_scale <- scale(train[, "AVG.STDNT.CUM.GPA"])
test_scale <- scale(test[, "AVG.STDNT.CUM.GPA"])
set.seed(120)
classifier_cl <- naiveBayes(SALARYCLASS ~ ., data = train)
classifier_cl
y_pred <- predict(classifier_cl, newdata = test)
cm <- table(test$SALARYCLASS, y_pred)
cm
confusionMatrix(cm)
data = read.csv("data-with-salary-class.csv")
dimnames(data)
split <- sample.split(data, SplitRatio = 0.7)
train <- subset(data, split == "TRUE")
test <- subset(data, split == "FALSE")
train_scale <- scale(train[, 17:38])
test_scale <- scale(test[, 17:38])
set.seed(120)
classifier_cl <- naiveBayes(SALARYCLASS ~ ., data = train)
classifier_cl
y_pred <- predict(classifier_cl, newdata = test)
cm <- table(test$SALARYCLASS, y_pred)
cm
confusionMatrix(cm)
data = read.csv("data-with-inflation.csv")
data
dimnames(data)
data[1,"NEWSALARY"]
# Creating classes for salaries
for (i in 1:nrow(data)) {
if (data[i,"NEWSALARY"] <= 75000) {
data[i,"SALARYCLASS"] = 0
}
else if (data[i,"NEWSALARY"] <= 100000) {
data[i,"SALARYCLASS"] = 1
}
else if (data[i,"NEWSALARY"] <= 125000) {
data[i,"SALARYCLASS"] = 2
}
else if (data[i,"NEWSALARY"] <= 150000) {
data[i,"SALARYCLASS"] = 3
}
else if (data[i,"NEWSALARY"] <= 175000) {
data[i,"SALARYCLASS"] = 4
}
else if (data[i,"NEWSALARY"] <= 200000) {
data[i,"SALARYCLASS"] = 5
}
else if (data[i,"NEWSALARY"] > 200000) {
data[i,"SALARYCLASS"] = 6
}
}
data[1,"SALARYCLASS"]
write.csv(data, "data-with-salary-class.csv")
data[1,"SALARYCLASS"]
write.csv(data, "data-with-salary-class.csv")
